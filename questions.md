Questions from the end of the exercise
---------------------------------------

1. Describe the most difficult/painful hurdle you had to overcome in implementing your solution.
   * The most difficult part for me was to KISS (KEEP IT SIMPLE SILLY). Having managed multiple puppet environments, I wanted to start with our "default" roles and profiles that manages multiple aspects of the machine specific to our setup, but once I looked at the puppet modules involved, I realized it would be a *very* short answer in the end.

2. Describe which Puppet-Â­related concept you think is the hardest for new users to grasp.
   * Honestly, I think the biggest problem I have seen is when people believe they need to invent everything from scratch, but I haven't really worked too many "new" puppet users. There are modules for almost everything we could ever possibly need. Sometimes we need to make a new module, but usually there is something that is close enough. The other side of this is that they need to be able to find a "good" module among the cruft. Puppet Labs has been helping that by introducing the rating system, but we still need to be able to look at the module code to decide for ourselves whether it does what we want it to do.

3. Please comment on the concept embodied by the second requirement of the solution (ii) as it relates to Puppet.
   * I assume this is referring to idempotency. This is very important since puppet runs every half hour by default. If it just continually applied the configurations, it would cause a lot of unnecessary overhead and quite likely availability issues. In Puppet, we define the desired state, and in very few cases, we define how to get to the desired state. Puppet ensures that the system is configured according to the definition and if it is, it leaves it alone. If the system is not in the desired state, then it makes it so. There are situations when that can break, which is why it is important to review puppet errors as quickly as possible, and have a *clean* puppet run during normal circumstances.

4. Where did you go to find information to help you in the build process?
   * I mostly visited the documentation on Module Forge for the various modules that I used (puppetlabs-vcsrepo, jfryman-nginx). Otherwise, I considered this exercise to be fairly elementary.

5. In a couple paragraphs explain what automation means to you and why it is important to an organization's infrastructure design strategy.

     Automation is a logical step forward for most IT organizations. In the old days, there was a Systems Administrator (sysadmin) that knew how everything worked, and where to look when something was not working quite right. Every machine was special to the sysadmin, and most sysadmins used special names to refer to their "pet" machines. As time goes on, more and more systems are added, and some systems have the need to scale up to multiple instances. After a while, the sysadmin had too many systems to work on and had to hire another sysadmin. This other sysadmin had no idea how any of this stuff worked or how to fix it if something went wrong. In addition to that, the new sysadmin, and in some cases, even the original sysadmin will have no idea what to do if "zeus" fails and needs to be rebuilt. 

     Some sysadmins kept extensive notes, in case they should ever run into "that" problem again, but they were rarely useful to anyone but the person who wrote them originally. These notes, combined with a lot of time to re-figure everything out again would eventually bring "zeus" back to life. Some organizations actually keep very extensive documentation, well formatted, and rarely updated. Yes, the best IT organization practices include a build document, a run document, and change control. In most cases, they still should. Enter automation, sysadmins should no longer make any changes directly to a server. Instead they change code that defines the desired state of the server, and the automation platform makes the server compliant. This means that if a server ever needs to be rebuilt or cloned for testing, it should really be a very simple operation. Automation also protects against unauthorized changes because it will revert changes in any managed service during the next run because it does not match the defined or desired state. By only ever making changes to the "code" that defines the "infrastructure" we can ensure that there are no "undocumented" changes to the servers. Automation is very much a mindset that must be adopted, and everyone must adopt it. Initially some things will take longer, but in the end, whether it is in a moment of great success, where we need to scale up a service, or whether it is during bad times when something becomes compromised or destroyed, the automation system will save us a lot of time and money.

